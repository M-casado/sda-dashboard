version: "3.7"
services:
  db:
    command: server /data
    container_name: db
    environment:
      - DB_LEGA_IN_PASSWORD=lega_in
      - DB_LEGA_OUT_PASSWORD=lega_out
      - NOTLS=true
    healthcheck:
      test: ["CMD", "pg_isready", "-h", "localhost", "-U", "lega_out"]
      interval: 5s
      timeout: 20s
      retries: 3
    image: neicnordic/sda-db:v2.0.0beta1
    ports:
      - "5432:5432"
    volumes:
      - /tmp/data:/var/lib/postgresql/data
  mq:
    image: neicnordic/sda-mq:v1.4.13
    container_name: mq
    environment:
     - MQ_USER=test
     - MQ_PASSWORD_HASH=C5ufXbYlww6ZBcEqDUB04YdUptO81s+ozI3Ll5GCHTnv8NAm
     - MQ_VHOST=test
     - NOTLS=true
    ports:
      - "15672:15672"
      - "5672:5672"
    healthcheck:
      test: [ "CMD", "bash", "-c", "rabbitmq-diagnostics -q check_running && rabbitmq-diagnostics -q check_local_alarms"]
      interval: 5s
      timeout: 20s
      retries: 3
  s3:
    command: server /data --console-address ":9001"
    container_name: s3
    environment:
      - MINIO_NOTIFY_ELASTICSEARCH_ENABLE=on
      - MINIO_NOTIFY_ELASTICSEARCH_URL=http://elasticsearch:9200
      - MINIO_NOTIFY_ELASTICSEARCH_INDEX=minio
      - MINIO_NOTIFY_ELASTICSEARCH_FORMAT=namespace
      - MINIO_ACCESS_KEY=access
      - MINIO_SECRET_KEY=secretkey
      - MINIO_SERVER_URL=http://127.0.0.1:9000
    healthcheck:
      test: ["CMD", "curl", "-fq", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 20s
      retries: 3
    image: minio/minio:RELEASE.2022-09-25T15-44-53Z
    ports:
      - "9000:9000"
      - "9001:9001"
  createbucket:
    image: minio/mc
    container_name: mc
    depends_on:
      s3:
        condition: service_started
    entrypoint: >
      /bin/sh -c "
      sleep 10;
      /usr/bin/mc -q config host add s3 http://s3:9000 access secretkey;
      /usr/bin/mc -q mb s3/inbox || true;
      /usr/bin/mc -q mb s3/archive || true;
      /usr/bin/mc -q mb s3/backup || true;
      exit 0;
      "
  ingest:
    command: sda-ingest
    container_name: ingest
    depends_on:
      db:
        condition: service_started
      mq:
        condition: service_healthy
      s3:
        condition: service_started
      bootstrap:
        condition: service_started
    environment:
      - ARCHIVE_TYPE=s3
      - ARCHIVE_URL=http://s3
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=ingest
      - BROKER_ROUTINGKEY=archived
      - BROKER_ROUTINGERROR=error
      - DB_HOST=db
      - INBOX_TYPE=s3
      - INBOX_URL=http://s3
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
      - archive:/tmp
    restart: always
  verify:
    command: sda-verify
    container_name: verify
    depends_on:
      db:
        condition: service_started
      mq:
        condition: service_healthy
      s3:
        condition: service_started
    environment:
      - ARCHIVE_URL=http://s3
      - ARCHIVE_TYPE=s3
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=archived
      - BROKER_ROUTINGKEY=verified
      - BROKER_ROUTINGERROR=error
      - DB_HOST=db
      - INBOX_TYPE=s3
      - INBOX_URL=http://s3
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
      - archive:/tmp
    restart: always
  finalize:
    command: sda-finalize
    container_name: finalize
    depends_on:
      db:
        condition: service_started
      mq:
        condition: service_healthy
    environment:
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=accessionIDs
      - BROKER_ROUTINGKEY=backup
      - BROKER_ROUTINGERROR=error
      - DB_HOST=db
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
    restart: always
  backup:
    command: sda-backup
    container_name: backup
    depends_on:
      db:
        condition: service_started
      mq:
        condition: service_healthy
      s3:
        condition: service_started
    environment:
      - ARCHIVE_TYPE=s3
      - ARCHIVE_URL=http://s3
      - BACKUP_TYPE=s3
      - BACKUP_URL=http://s3
      - BACKUP_LOCATION=/backup
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=backup
      - BROKER_ROUTINGKEY=completed
      - BROKER_ROUTINGERROR=error
      - DB_HOST=db
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
      - archive:/tmp
      - backup:/backup
    restart: always
  mapper:
    command: sda-mapper
    container_name: mapper
    depends_on:
      db:
        condition: service_started
      mq:
        condition: service_healthy
    environment:
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=mappings
      - BROKER_ROUTINGERROR=error
      - DB_HOST=db
      - DB_USER=lega_out
      - DB_PASSWORD=lega_out
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
    restart: always
  interceptor:
    command: sda-intercept
    depends_on:
      mq:
        condition: service_healthy
    environment:
      - BROKER_EXCHANGE=sda
      - BROKER_HOST=mq
      - BROKER_QUEUE=files
      - BROKER_ROUTINGKEY=ingest
      - BROKER_ROUTINGERROR=error
    image: neicnordic/sda-pipeline:latest
    volumes:
      - ./config.yaml:/config.yaml
      - keys:/keys
    restart: always
  bootstrap:
    depends_on:
      createbucket:
        condition: service_completed_successfully
      mq:
        condition: service_healthy
      s3:
        condition: service_started
      db:
        condition: service_started
    command: sh -c /bin/bootstrap.sh -p /keys/c4gh.pub
    container_name: bs
    image: neicnordic/sda-helm-tests-support:latest
    user: 0:0
    volumes:
      - $PWD/scripts/bootstrap.sh:/bin/bootstrap.sh
      - keys:/keys
  elasticsearch:
    image: "docker.elastic.co/elasticsearch/elasticsearch:7.16.3"
    environment:
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - "discovery.type=single-node"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
  kibana:
    image: "docker.elastic.co/kibana/kibana:7.16.3"
    ports:
      - "5601:5601"
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      ELASTICSERCH_URL: http://elasticsearch:9200
    volumes:
      - grafana_data:/var/lib/grafana
  filebeat:
    image: "docker.elastic.co/beats/filebeat:7.16.3"
    user: root
    volumes:
    - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    - /var/lib/docker:/var/lib/docker:ro
    - /var/run/docker.sock:/var/run/docker.sock
volumes:
  grafana_data:
  elasticsearch_data:
  keys:
  archive:
  backup:
